{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8dc4a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Gauri Fargade\\Desktop\\jupyter projects\\.ipynb_checkpoints\"\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"Dataset folder found at: {dataset_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Dataset folder NOT found! Please check the path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586e974",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_folder = os.path.join(dataset_folder, \"TRAIN\")\n",
    "test_folder = os.path.join(dataset_folder, \"TEST\")\n",
    "train_images = os.listdir(train_folder) if os.path.exists(train_folder) else []\n",
    "test_images = os.listdir(test_folder) if os.path.exists(test_folder) else []\n",
    "\n",
    "print(f\" Number of images in TRAIN folder: {len(train_images)}\")\n",
    "print(f\" Number of images in TEST folder: {len(test_images)}\")\n",
    "\n",
    "\n",
    "print(\" Train Folder Images:\", os.listdir(train_folder))\n",
    "print(\" Test Folder Images:\", os.listdir(test_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073fe822",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_o_images = os.listdir(train_o_path)\n",
    "train_r_images = os.listdir(train_r_path)\n",
    "\n",
    "test_o_images = os.listdir(test_o_path)\n",
    "test_r_images = os.listdir(test_r_path)\n",
    "\n",
    "print(f\" Number of images in TRAIN/O: {len(train_o_images)}\")\n",
    "print(f\" Number of images in TRAIN/R: {len(train_r_images)}\")\n",
    "print(f\" Number of images in TEST/O: {len(test_o_images)}\")\n",
    "print(f\" Number of images in TEST/R: {len(test_r_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba4885",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "IMG_SIZE = 128  \n",
    "\n",
    "\n",
    "def load_images_from_folder(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in tqdm(os.listdir(folder_path), desc=f\"Processing {label} images\"):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path)  # Read image\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # Resize\n",
    "            img = img / 255.0  # Normalize pixel values\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "train_o_images, train_o_labels = load_images_from_folder(train_o_path, label=0)  # Organic = 0\n",
    "train_r_images, train_r_labels = load_images_from_folder(train_r_path, label=1)  # Reusable = 1\n",
    "\n",
    "\n",
    "test_o_images, test_o_labels = load_images_from_folder(test_o_path, label=0)\n",
    "test_r_images, test_r_labels = load_images_from_folder(test_r_path, label=1)\n",
    "\n",
    "\n",
    "X_train = np.array(train_o_images + train_r_images)\n",
    "y_train = np.array(train_o_labels + train_r_labels)\n",
    "\n",
    "X_test = np.array(test_o_images + test_r_images)\n",
    "y_test = np.array(test_o_labels + test_r_labels)\n",
    "\n",
    "\n",
    "np.save(\"train_data_preprocessed.npy\", X_train)\n",
    "np.save(\"train_labels_encoded.npy\", y_train)\n",
    "np.save(\"test_data_preprocessed.npy\", X_test)\n",
    "np.save(\"test_labels_encoded.npy\", y_test)\n",
    "\n",
    "print(\"✅ Image preprocessing complete!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1bff1d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23f3d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values (0-1)\n",
    "    validation_split=0.2  # Splitting 20% of training data for validation\n",
    ")\n",
    "\n",
    "\n",
    "dataset_path = r\"C:\\Users\\Gauri Fargade\\Desktop\\jupyter projects\\.ipynb_checkpoints\\DATASET\\TRAIN\"\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,  \n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,  \n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "print(\" Data is now loaded using generators! No MemoryError!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866f258",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Prevents overfitting\n",
    "    Dense(1, activation='sigmoid')  # Binary classification (O vs R)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a747e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,  # Normalize pixel values\n",
    "    rotation_range=20,   # Random rotation\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Only rescale for validation\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Users/Gauri Fargade/Desktop/jupyter projects/.ipynb_checkpoints/DATASET/TRAIN',\n",
    "    target_size=(128, 128),  # Resize images\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Use 'categorical' if you have more than 2 classes\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    'C:/Users/Gauri Fargade/Desktop/jupyter projects/.ipynb_checkpoints/DATASET/TEST',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "print(\" Data generators are ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e246b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Adjust as needed\n",
    "    validation_data=validation_generator\n",
    ")`\n",
    "\n",
    "# Save model\n",
    "model.save(\"waste_classification_model.h5\")\n",
    "\n",
    "print(\"Training complete! Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013fea49",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dbdc2c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"waste_classification_model.h5\")\n",
    "\n",
    "# Define path to the test dataset\n",
    "test_dir = \"C:/Users/Gauri Fargade/Desktop/jupyter projects/.ipynb_checkpoints/DATASET/TEST\"\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = {0: \"Organic Waste\", 1: \"Recyclable Waste\"}  # Adjust if needed\n",
    "\n",
    "# Function to preprocess an image for prediction\n",
    "def preprocess_image(image_path, target_size=(128, 128)):\n",
    "    img = load_img(image_path, target_size=target_size)  # Load image\n",
    "    img = img_to_array(img) / 255.0  # Convert to array and normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Get all images in the TEST directory\n",
    "for category in [\"O\", \"R\"]:  # 'O' for Organic, 'R' for Recyclable\n",
    "    category_path = os.path.join(test_dir, category)\n",
    "    for img_name in os.listdir(category_path):\n",
    "        img_path = os.path.join(category_path, img_name)\n",
    "        \n",
    "        # Preprocess the image\n",
    "        img = preprocess_image(img_path)\n",
    "        \n",
    "        # Predict the class\n",
    "        prediction = model.predict(img)\n",
    "        predicted_class = 1 if prediction[0][0] > 0.5 else 0  # 0: Organic, 1: Recyclable\n",
    "        \n",
    "        # Display the result\n",
    "        plt.figure()\n",
    "        plt.imshow(load_img(img_path))  # Show image\n",
    "        plt.title(f\"Predicted: {class_labels[predicted_class]}\\nActual: {class_labels[1] if category == 'R' else class_labels[0]}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b18aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"waste_classification_model.h5\")\n",
    "\n",
    "# Define class labels (assuming 0 = Organic, 1 = Reusable)\n",
    "class_labels = {0: \"Organic\", 1: \"Reusable\"}\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path, target_size=(128, 128)):\n",
    "    img = cv2.imread(image_path)  # Read the image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = cv2.resize(img, target_size)  # Resize image to match model input\n",
    "    img = img / 255.0  # Normalize pixel values (0-1)\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Path to the folder containing test images\n",
    "test_folder = \"C:/Users/Gauri Fargade/Desktop/jupyter projects/.ipynb_checkpoints/DATASET/TEST\"\n",
    "\n",
    "# Loop through test images\n",
    "for category in [\"O\", \"R\"]:  # Folders for Organic (O) and Reusable (R)\n",
    "    category_path = os.path.join(test_folder, category)\n",
    "    for image_name in os.listdir(category_path):\n",
    "        image_path = os.path.join(category_path, image_name)\n",
    "        image_data = preprocess_image(image_path)\n",
    "\n",
    "        # Predict class (0 or 1)\n",
    "        prediction = model.predict(image_data)\n",
    "        predicted_class = 1 if prediction[0][0] > 0.5 else 0  # Threshold at 0.5\n",
    "\n",
    "        # Print result\n",
    "        print(f\"Image: {image_name} → Predicted: {predicted_class} ({class_labels[predicted_class]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2318d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"waste_classification_model.h5\")\n",
    "\n",
    "# Define class labels (assuming 0 = Organic, 1 = Reusable)\n",
    "class_labels = {0: \"Organic\", 1: \"Reusable\"}\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path, target_size=(128, 128)):\n",
    "    img = cv2.imread(image_path)  # Read the image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = cv2.resize(img, target_size)  # Resize image to match model input\n",
    "    img = img / 255.0  # Normalize pixel values (0-1)\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Path to the folder containing test images\n",
    "test_folder = \"C:/Users/Gauri Fargade/Desktop/jupyter projects/.ipynb_checkpoints/DATASET/TEST\"\n",
    "\n",
    "# Loop through test images\n",
    "for category in [\"O\", \"R\"]:  # Folders for Organic (O) and Reusable (R)\n",
    "    category_path = os.path.join(test_folder, category)\n",
    "    image_names = sorted(os.listdir(category_path))  # Sort images in order\n",
    "    \n",
    "    # Select first 3 and last 2 images\n",
    "    selected_images = image_names[:3] + image_names[-2:]\n",
    "\n",
    "    print(f\"\\nPredictions for category: {category}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(selected_images), figsize=(15, 5))  # Create subplots\n",
    "\n",
    "    for i, image_name in enumerate(selected_images):\n",
    "        image_path = os.path.join(category_path, image_name)\n",
    "        image_data = preprocess_image(image_path)\n",
    "\n",
    "        # Predict the class\n",
    "        prediction = model.predict(image_data)\n",
    "        predicted_class = int(round(prediction[0][0]))  # Convert to 0 or 1\n",
    "\n",
    "        # Read the image for displaying\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Show the image with prediction\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"{image_name}\\nPredicted: {class_labels[predicted_class]}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.show()  # Display the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a89d514",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"waste_classification_model.h5\")\n",
    "\n",
    "# Define class labels\n",
    "class_labels = {0: \"Organic\", 1: \"Reusable\"}\n",
    "\n",
    "# Function to preprocess an image\n",
    "def preprocess_image(image_path, target_size=(128, 128)):\n",
    "    img = cv2.imread(image_path)  # Read the image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img = cv2.resize(img, target_size)  # Resize image to match model input\n",
    "    img = img / 255.0  # Normalize pixel values (0-1)\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "# Path to the folder containing test images\n",
    "test_folder = r\"C:\\Users\\Gauri Fargade\\Pictures\\test\"\n",
    "\n",
    "# Get the list of image files in the folder\n",
    "image_files = sorted(os.listdir(test_folder))  # Sort to ensure correct order\n",
    "\n",
    "# Loop through all images in the folder\n",
    "for image_name in image_files:\n",
    "    image_path = os.path.join(test_folder, image_name)\n",
    "    \n",
    "    # Preprocess and predict\n",
    "    image_data = preprocess_image(image_path)\n",
    "    prediction = model.predict(image_data)\n",
    "    \n",
    "    # Convert prediction to 0 or 1\n",
    "    predicted_class = int(prediction[0][0] > 0.5)  # 0 = Organic, 1 = Reusable\n",
    "    \n",
    "    # Display image with prediction\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Predicted: {class_labels[predicted_class]}\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
